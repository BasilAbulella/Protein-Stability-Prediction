#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Apr  2 11:47:04 2024

@author: abulellab
"""

import numpy as np
import tensorflow as tf

# Make numpy values easier to read.
np.set_printoptions(precision=3, suppress=True)

from sklearn.model_selection import KFold
from scipy.stats import pearsonr
from modules.functions import (make_model, 
                               learning_rate_scheduler,
                               evaluation,
                               get_best_epochs)

def train_model(
    features,
    target,
    dataset,
    n_folds,
    activation,
    dropout,
    nodes,
    epochs,
    batch_sizes,
    saving_dir,
    file_name
):
    
    kf = KFold(
        n_splits=n_folds, shuffle=True, random_state=11)

    # lists to collect data from the nfold loops
    scores                                  = []  
    allfolds_training_loss                  = []  
    allfolds_validation_loss                = []  
    y_predall_train                         = []
    y_predall_val                           = []
    y_actualall_train                          = []
    y_actualall_val                            = []
    pearson_coeff_train_all                 = np.array([])
    pearson_coeff_val_all                   = np.array([])
    # list of lowest loss per fold
    best_epoch_all                          = np.array([])  

    y_predall_train_sorted = np.zeros(len(target), dtype=float) 
    y_predall_val_sorted   = np.zeros(len(target), dtype=float) 

    # cross validation loop where we Iterate over each fold
    for train_index, val_index in kf.split(features):  
        X_train, X_val = (
            features.iloc[train_index],
            features.iloc[val_index])  
        
        # Split the data into train and validation sets for this fold
        y_train, y_val = target.iloc[train_index], target.iloc[val_index]
        
        # make model
        dataset_model = make_model(features, nodes, dropout, activation)  
        optimizer = learning_rate_scheduler(target, batch_sizes, epochs) 
        
        # Compile the model
        dataset_model.compile(
            loss=tf.keras.losses.MeanAbsoluteError(), optimizer=optimizer) 
        # Fitting the model
        history = dataset_model.fit(  
            X_train,
            y_train,
            epochs=epochs,
            batch_size=batch_sizes,
            validation_data=(X_val, y_val))  
        
        # used the splitted data as the validation data to avoid splitting twice
        y_pred_train, y_pred_val, y_train, y_val = evaluation(dataset_model, 
                                                              X_train, X_val, 
                                                              y_train, y_val, 
                                                              scores, 
                                                              allfolds_training_loss, 
                                                              allfolds_validation_loss,
                                                              history) 

        # collecting & generating the data across all cross validations
        y_predall_train += list(y_pred_train.flatten())  
        y_actualall_train += list(y_train)
        
        y_predall_val += list(y_pred_val.flatten())
        y_actualall_val += list(y_val)

        best_epoch, best_val_epoch = get_best_epochs(history)
        best_epoch_all = np.append(best_epoch_all, best_val_epoch)
        
        val_list = list (y_pred_val.flatten())
        for i in range(len(val_index)):
            y_predall_val_sorted[val_index[i]] = val_list[i]


        # Pearson correlation coefficient 
        #pearson_coeff_train, _ = pearsonr(
        #    y_actual_val, 
        #    y_predall_val)
        pearson_coeff_train, _ = pearsonr(
            y_pred_train,
            y_train)
        print("pearson_coeff_train",pearson_coeff_train)
        
        #pearson_coeff_train_all = np.append(
        #    pearson_coeff_train_all, 
        #    pearson_coeff_train)

        # Pearson correlation coefficient for the val_set
        pearson_coeff_val, _ = pearsonr(
            y_pred_val, 
            y_val)  
        print("pearson_coeff_val",pearson_coeff_val)
        
        pearson_coeff_val_all = np.append(
            pearson_coeff_val_all, 
            pearson_coeff_val)
        print("pearson_coeff_val_all",pearson_coeff_val_all)



        #train_list = list (y_pred_train.flatten())
        #for i in range(len(train_index)):
        #    y_predall_train_sorted[train_index[i]] = train_list[i]


    print("mean val",np.mean(pearson_coeff_val_all))
    print(pearsonr(
        y_predall_train ,
        y_actualall_train))
    
    print(pearsonr(
        y_predall_val,
        y_actualall_val))

        
    #pearson_coeff_train_sorted, _ = pearsonr(y_predall_train_sorted, target)
    pearson_coeff_val_sorted, _   = pearsonr(y_predall_val_sorted, target)        
    
    #print("sorted pearson train: ", pearson_coeff_val_sorted)
    print("sorted pearson val: " ,pearson_coeff_val_sorted)
        
        
                
        
    saved_data = {
        'y_actual_train':             y_actual_train,
        'y_actual_val':               y_actual_val,
        'y_pred_train':               y_pred_train,
        'y_pred_val':                 y_pred_val,
        'y_predall_train':            y_predall_train,
        'y_predall_val':              y_predall_val,
        'allfolds_training_loss':     allfolds_training_loss,
        'allfolds_validation_loss':   allfolds_validation_loss,
        'best_epoch_all':             best_epoch_all,
        'scores':                     scores,
        'pearson_coeff_train_all':    pearson_coeff_train_all,
        'pearson_coeff_val_all':      pearson_coeff_val_all,
        'dataset_model':              dataset_model,
        'history':                    history,
        'n_folds':                    n_folds,
        'target':                     target,
        'train_index':                train_index,
        'val_index':                  val_index,
        'y_predall_train_sorted':     y_predall_train_sorted,
        'y_predall_val_sorted':       y_predall_val_sorted
        }
    
    
    np.save((saving_dir + file_name +  "_saved_data.npy"), saved_data)

    return (
        X_train,
        X_val,
        y_train,
        y_val,
        y_actual_train,
        y_actual_val,
        y_pred_train,
        y_pred_val,
        y_predall_train,
        y_predall_val,
        allfolds_training_loss,
        allfolds_validation_loss,
        best_epoch_all,
        scores,
        pearson_coeff_train_all,
        pearson_coeff_val_all,
        dataset_model,
        history,
    )
